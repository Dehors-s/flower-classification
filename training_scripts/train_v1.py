import paddle
import paddle.nn as nn
import paddle.vision.transforms as T
from paddle.io import DataLoader, Dataset
from paddle.optimizer import AdamW
from paddle.optimizer.lr import CosineAnnealingDecay, LinearWarmup
import os
import numpy as np
import time
import csv  # ä½¿ç”¨csvæ›¿ä»£pandas
from PIL import Image
import random
import math

print(f"PaddlePaddleç‰ˆæœ¬: {paddle.__version__}")


# ä¼˜åŒ–çš„ViTé…ç½® - å‡å°æ¨¡å‹è§„æ¨¡
class OptimizedViTConfig:
    data_dir = r'D:\ptcharm\project\èŠ±å‰åˆ†æ'

    # ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥
    image_size_stage1 = 224  # ç¬¬ä¸€é˜¶æ®µä½¿ç”¨224
    image_size_stage2 = 384  # ç¬¬äºŒé˜¶æ®µå¾®è°ƒä½¿ç”¨384

    patch_size = 16
    num_classes = 100
    batch_size_stage1 = 16  # ç¬¬ä¸€é˜¶æ®µå¯ä»¥ç”¨æ›´å¤§çš„batch
    batch_size_stage2 = 16  # ç¬¬äºŒé˜¶æ®µå‡å°batch

    # å‡å°æ¨¡å‹è§„æ¨¡ä»¥é€‚åº”æ•°æ®é›†
    dim = 384  # å‡å°åµŒå…¥ç»´åº¦
    depth = 6  # å‡å°‘å±‚æ•°
    heads = 8  # ä¿æŒæ³¨æ„åŠ›å¤´
    mlp_ratio = 4
    dropout = 0.2  # å¢åŠ dropouté˜²æ­¢è¿‡æ‹Ÿåˆ

    # å­¦ä¹ ç‡é…ç½®
    learning_rate_stage1 = 1e-4
    learning_rate_stage2 = 5e-5  # å¾®è°ƒæ—¶ä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡
    weight_decay = 1e-4
    warmup_epochs = 5
    num_epochs_stage1 = 50
    num_epochs_stage2 = 30

    save_dir = r'D:\ptcharm\project\èŠ±å‰åˆ†æ\output_vit_optimized'

    # æ–­ç‚¹ç»§ç»­é…ç½®
    resume_stage1 = None  # è®¾ç½®ä¸ºå…·ä½“è·¯å¾„å¦‚ '/home/aistudio/work/output_vit_optimized/checkpoint_stage1_epoch_20.pdparams'
    resume_stage2 = None  # ç¬¬äºŒé˜¶æ®µæ¢å¤è·¯å¾„

    log_interval = 20

    os.makedirs(save_dir, exist_ok=True)


def setup_memory_optimization():
    """è®¾ç½®å†…å­˜ä¼˜åŒ–é…ç½®"""
    # å¼€å¯æ˜¾å­˜åƒåœ¾å›æ”¶
    os.environ['FLAGS_eager_delete_tensor_gb'] = '0'
    os.environ['FLAGS_fast_eager_deletion_mode'] = 'True'
    os.environ['FLAGS_memory_fraction_of_eager_deletion'] = '1'

    # è°ƒæ•´æ˜¾å­˜åˆ†é…ç­–ç•¥
    os.environ['FLAGS_fraction_of_gpu_memory_to_use'] = '0.9'

    # è®¾ç½®å·ç§¯å·¥ä½œç©ºé—´å¤§å°é™åˆ¶
    os.environ['FLAGS_conv_workspace_size_limit'] = '512'


def count_parameters(model):
    total_params = 0
    for param in model.parameters():
        total_params += int(param.numel())
    return total_params


class RandomGrayscale:
    def __init__(self, p=0.1):
        self.p = p

    def __call__(self, img):
        if random.random() < self.p:
            if isinstance(img, paddle.Tensor):
                if img.shape[0] == 3:
                    gray = 0.299 * img[0] + 0.587 * img[1] + 0.114 * img[2]
                    img = paddle.stack([gray, gray, gray], axis=0)
            else:
                img = img.convert('L').convert('RGB')
        return img


class LabelSmoothingCrossEntropy(nn.Layer):
    def __init__(self, smoothing=0.1):
        super().__init__()
        self.smoothing = smoothing

    def forward(self, x, target):
        confidence = 1.0 - self.smoothing

        logprobs = nn.functional.log_softmax(x, axis=-1)

        # å¤„ç†è½¯æ ‡ç­¾å’Œç¡¬æ ‡ç­¾
        if len(target.shape) > 1 and target.shape[-1] == x.shape[-1]:
            # è½¯æ ‡ç­¾æƒ…å†µ (MixUp)
            targets = target
        else:
            # ç¡¬æ ‡ç­¾æƒ…å†µ
            targets = paddle.nn.functional.one_hot(
                target.astype('int64'),
                num_classes=x.shape[-1]
            )
            targets = targets * (1 - self.smoothing) + self.smoothing / x.shape[-1]

        # æ›´å®‰å…¨çš„æŸå¤±è®¡ç®—
        nll_loss = - (targets * logprobs).sum(axis=-1)
        loss = nll_loss.mean()

        return loss


# ä¼˜åŒ–çš„ViTæ¨¡å‹ - æ·»åŠ æ›´å¤šæ­£åˆ™åŒ–
class OptimizedViT(nn.Layer):
    def __init__(self, image_size=224, patch_size=16, num_classes=1000,
                 dim=384, depth=6, heads=8, mlp_ratio=4, dropout=0.2):
        super().__init__()

        self.patch_size = patch_size
        self.num_patches = (image_size // patch_size) ** 2

        # PatchåµŒå…¥
        self.patch_embed = nn.Conv2D(
            3, dim,
            kernel_size=patch_size,
            stride=patch_size
        )

        # ç±»åˆ«tokenå’Œä½ç½®ç¼–ç 
        self.cls_token = self.create_parameter(
            shape=[1, 1, dim],
            default_initializer=nn.initializer.TruncatedNormal(std=0.02)
        )
        self.pos_embedding = self.create_parameter(
            shape=[1, self.num_patches + 1, dim],
            default_initializer=nn.initializer.TruncatedNormal(std=0.02)
        )

        self.dropout = nn.Dropout(dropout)

        # Transformerå±‚
        mlp_dim = int(dim * mlp_ratio)
        self.encoder_layers = nn.LayerList([
            TransformerBlock(dim, heads, mlp_dim, dropout)
            for _ in range(depth)
        ])

        # å±‚å½’ä¸€åŒ–
        self.norm = nn.LayerNorm(dim)

        # å¢å¼ºçš„åˆ†ç±»å¤´ - æ·»åŠ dropout
        self.head = nn.Sequential(
            nn.Dropout(0.3),
            nn.Linear(dim, 512),
            nn.GELU(),
            nn.Dropout(0.2),
            nn.Linear(512, num_classes)
        )

        # åˆå§‹åŒ–æƒé‡
        self.apply(self._init_weights)

    def _init_weights(self, m):
        if isinstance(m, nn.Linear):
            nn.initializer.TruncatedNormal(std=0.02)(m.weight)
            if m.bias is not None:
                nn.initializer.Constant(0)(m.bias)
        elif isinstance(m, nn.LayerNorm):
            nn.initializer.Constant(0)(m.bias)
            nn.initializer.Constant(1.0)(m.weight)
        elif isinstance(m, nn.Conv2D):
            nn.initializer.TruncatedNormal(std=0.02)(m.weight)
            if m.bias is not None:
                nn.initializer.Constant(0)(m.bias)

    def forward(self, x):
        B, C, H, W = x.shape

        x = self.patch_embed(x)
        x = x.flatten(2)
        x = x.transpose([0, 2, 1])

        cls_tokens = self.cls_token.expand([B, -1, -1])
        x = paddle.concat([cls_tokens, x], axis=1)

        x = x + self.pos_embedding
        x = self.dropout(x)

        for layer in self.encoder_layers:
            x = layer(x)

        x = self.norm(x)
        x = x[:, 0]
        x = self.head(x)

        return x


class TransformerBlock(nn.Layer):
    def __init__(self, dim, heads, mlp_dim, dropout=0.1):
        super().__init__()
        self.norm1 = nn.LayerNorm(dim)
        self.attn = nn.MultiHeadAttention(dim, heads, dropout=dropout)
        self.norm2 = nn.LayerNorm(dim)
        self.mlp = nn.Sequential(
            nn.Linear(dim, mlp_dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(mlp_dim, dim),
            nn.Dropout(dropout)
        )
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        residual = x
        x = self.norm1(x)
        attn_output = self.attn(x, x, x)
        x = residual + self.dropout(attn_output)

        residual = x
        x = self.norm2(x)
        mlp_output = self.mlp(x)
        x = residual + self.dropout(mlp_output)

        return x


class FlowerDataset(Dataset):
    def __init__(self, data_dir, transform=None, use_mixup=False, alpha=0.2):
        self.data_dir = data_dir
        self.transform = transform
        self.use_mixup = use_mixup
        self.alpha = alpha
        self.samples = []
        self.labels = []

        categories = sorted([d for d in os.listdir(data_dir) if d.isdigit()], key=int)
        self.label_mapping = {int(cat): idx for idx, cat in enumerate(categories)}
        self.num_classes = len(categories)

        print(f"åŠ è½½æ•°æ®é›†: {data_dir}")
        print(f"å‘ç°ç±»åˆ«: {len(categories)}ä¸ª")

        for category in categories:
            category_dir = os.path.join(data_dir, category)
            if os.path.isdir(category_dir):
                for file in os.listdir(category_dir):
                    if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                        self.samples.append(os.path.join(category_dir, file))
                        self.labels.append(self.label_mapping[int(category)])

        print(f"å›¾ç‰‡æ•°é‡: {len(self.samples)}")

    def __getitem__(self, idx):
        img_path = self.samples[idx]
        label = self.labels[idx]

        try:
            img = Image.open(img_path).convert('RGB')
            if self.transform:
                img = self.transform(img)

            # ç®€å•çš„MixUpæ•°æ®å¢å¼º - è¿”å›ç¡¬æ ‡ç­¾ï¼Œé¿å…å½¢çŠ¶ä¸ä¸€è‡´é—®é¢˜
            if self.use_mixup and self.transform and np.random.random() < 0.5:
                mixup_idx = np.random.randint(0, len(self.samples))
                mixup_img_path = self.samples[mixup_idx]
                mixup_label = self.labels[mixup_idx]

                mixup_img = Image.open(mixup_img_path).convert('RGB')
                mixup_img = self.transform(mixup_img)

                lam = np.random.beta(self.alpha, self.alpha)
                img = lam * img + (1 - lam) * mixup_img

                # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬è¿”å›ç¡¬æ ‡ç­¾è€Œä¸æ˜¯è½¯æ ‡ç­¾
                # è¿™æ ·å¯ä»¥é¿å…æ•°æ®åŠ è½½å™¨ä¸­çš„å½¢çŠ¶ä¸ä¸€è‡´é—®é¢˜
                if lam > 0.5:
                    # è¿”å›åŸå§‹æ ‡ç­¾
                    label = label
                else:
                    # è¿”å›æ··åˆæ ‡ç­¾
                    label = mixup_label

            return img, label

        except Exception as e:
            print(f"åŠ è½½å›¾ç‰‡å¤±è´¥: {img_path}, é”™è¯¯: {e}")
            # è¿”å›æ­£ç¡®ç±»å‹çš„å ä½ç¬¦æ•°æ®
            dummy_img = paddle.zeros([3, OptimizedViTConfig.image_size_stage1,
                                      OptimizedViTConfig.image_size_stage1]).astype('float32')
            dummy_label = 0
            return dummy_img, dummy_label

    def __len__(self):
        return len(self.samples)


def create_optimized_transforms(image_size=224, is_training=True):
    if is_training:
        train_transforms = T.Compose([
            T.Resize((int(image_size * 1.1), int(image_size * 1.1))),
            T.RandomCrop(image_size),
            T.RandomHorizontalFlip(0.5),
            T.RandomRotation(10),
            # ä¿®æ”¹hueå‚æ•°ä¸ºéè´ŸèŒƒå›´ï¼Œé¿å…å‡ºç°è´Ÿæ•°å¯¼è‡´çš„uint8æº¢å‡º
            T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=(0, 0.1)),
            RandomGrayscale(p=0.1),
            T.ToTensor(),
            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        return train_transforms
    else:
        val_transforms = T.Compose([
            T.Resize((image_size, image_size)),
            T.ToTensor(),
            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        return val_transforms


def create_model(image_size=224):
    model = OptimizedViT(
        image_size=image_size,
        patch_size=OptimizedViTConfig.patch_size,
        num_classes=OptimizedViTConfig.num_classes,
        dim=OptimizedViTConfig.dim,
        depth=OptimizedViTConfig.depth,
        heads=OptimizedViTConfig.heads,
        mlp_ratio=OptimizedViTConfig.mlp_ratio,
        dropout=OptimizedViTConfig.dropout
    )

    print(f"åˆ›å»ºä¼˜åŒ–çš„ViTæ¨¡å‹")
    print(f"è¾“å…¥å°ºå¯¸: {image_size}")
    print(f"ç±»åˆ«æ•°: {OptimizedViTConfig.num_classes}")
    print(f"Patchæ•°é‡: {(image_size // OptimizedViTConfig.patch_size) ** 2}")

    total_params = count_parameters(model)
    print(f"æ€»å‚æ•°é‡: {total_params:,}")

    return model


def create_optimizer_scheduler(model, total_steps, learning_rate, num_epochs, warmup_epochs):
    warmup_steps = warmup_epochs * total_steps // num_epochs

    cosine_scheduler = CosineAnnealingDecay(
        learning_rate=learning_rate,
        T_max=total_steps - warmup_steps
    )

    scheduler = LinearWarmup(
        learning_rate=cosine_scheduler,
        warmup_steps=warmup_steps,
        start_lr=learning_rate * 0.01,
        end_lr=learning_rate
    )

    # åˆ›å»ºæ¢¯åº¦è£å‰ªå¯¹è±¡
    grad_clip = paddle.nn.ClipGradByGlobalNorm(clip_norm=1.0)

    # ä¿®æ­£ï¼šåŸºäºå‚æ•°åç§°åˆ¤æ–­æ˜¯å¦è¡°å‡ï¼Œè€Œä¸æ˜¯å‚æ•°å¯¹è±¡
    no_decay = ['bias', 'LayerNorm.weight']
    # æ”¶é›†ä¸éœ€è¦è¡°å‡çš„å‚æ•°åç§°
    no_decay_names = [n for n, p in model.named_parameters()
                      if any(nd in n for nd in no_decay)]

    # ä¼˜åŒ–å™¨å‚æ•°åˆ†ç»„ï¼ˆåŸºäºåç§°ï¼‰
    optimizer_grouped_parameters = [
        {
            'params': [p for n, p in model.named_parameters()
                       if not any(nd in n for nd in no_decay)],
            'weight_decay': OptimizedViTConfig.weight_decay,
        },
        {
            'params': [p for n, p in model.named_parameters()
                       if any(nd in n for nd in no_decay)],
            'weight_decay': 0.0,
        }
    ]

    optimizer = AdamW(
        parameters=optimizer_grouped_parameters,
        learning_rate=scheduler,
        weight_decay=OptimizedViTConfig.weight_decay,
        beta1=0.9,
        beta2=0.999,
        epsilon=1e-8,
        grad_clip=grad_clip,
        # ä¿®æ­£ï¼šåŸºäºå‚æ•°åç§°åˆ¤æ–­æ˜¯å¦åº”ç”¨è¡°å‡ï¼ˆxæ˜¯å‚æ•°åç§°å­—ç¬¦ä¸²ï¼‰
        apply_decay_param_fun=lambda x: x not in no_decay_names
    )

    return optimizer, scheduler

def load_checkpoint(model, optimizer=None, scheduler=None, checkpoint_path=None):
    """åŠ è½½æ£€æŸ¥ç‚¹ä»¥æ¢å¤è®­ç»ƒ"""
    if checkpoint_path is None or not os.path.exists(checkpoint_path):
        return 0, 0.0, [], [], [], []

    print(f"ğŸ”„ ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {checkpoint_path}")

    try:
        checkpoint = paddle.load(checkpoint_path)

        # åŠ è½½æ¨¡å‹çŠ¶æ€
        if 'model_state_dict' in checkpoint:
            model.set_state_dict(checkpoint['model_state_dict'])
            print("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")
        else:
            model.set_state_dict(checkpoint)
            print("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸï¼ˆç®€åŒ–æ ¼å¼ï¼‰")

        # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€
        if optimizer is not None and 'optimizer_state_dict' in checkpoint:
            optimizer.set_state_dict(checkpoint['optimizer_state_dict'])
            print("âœ… ä¼˜åŒ–å™¨çŠ¶æ€åŠ è½½æˆåŠŸ")

        # åŠ è½½è°ƒåº¦å™¨çŠ¶æ€
        if scheduler is not None and 'scheduler_state_dict' in checkpoint:
            scheduler.set_state_dict(checkpoint['scheduler_state_dict'])
            print("âœ… å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€åŠ è½½æˆåŠŸ")

        # åŠ è½½è®­ç»ƒçŠ¶æ€
        start_epoch = checkpoint.get('epoch', 0) + 1
        best_accuracy = checkpoint.get('best_accuracy', 0.0)

        # åŠ è½½è®­ç»ƒå†å²
        train_losses = checkpoint.get('train_losses', [])
        train_accuracies = checkpoint.get('train_accuracies', [])
        val_losses = checkpoint.get('val_losses', [])
        val_accuracies = checkpoint.get('val_accuracies', [])

        print(f"ğŸ“Š æ¢å¤è®­ç»ƒçŠ¶æ€: ä»epoch {start_epoch}å¼€å§‹, æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2f}%")

        return start_epoch, best_accuracy, train_losses, train_accuracies, val_losses, val_accuracies

    except Exception as e:
        print(f"âŒ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
        print("ğŸ”„ å°†ä»å¤´å¼€å§‹è®­ç»ƒ")
        return 0, 0.0, [], [], [], []


def save_checkpoint(epoch, model, optimizer, scheduler, best_accuracy,
                    train_losses, train_accuracies, val_losses, val_accuracies,
                    stage=1, is_best=False):
    """ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹"""
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict() if optimizer else None,
        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
        'best_accuracy': best_accuracy,
        'train_losses': train_losses,
        'train_accuracies': train_accuracies,
        'val_losses': val_losses,
        'val_accuracies': val_accuracies,
        'stage': stage,
        'config': {
            'image_size': OptimizedViTConfig.image_size_stage1 if stage == 1 else OptimizedViTConfig.image_size_stage2,
            'dim': OptimizedViTConfig.dim,
            'depth': OptimizedViTConfig.depth,
            'heads': OptimizedViTConfig.heads,
            'learning_rate': OptimizedViTConfig.learning_rate_stage1 if stage == 1 else OptimizedViTConfig.learning_rate_stage2,
        }
    }

    if is_best:
        checkpoint_path = os.path.join(OptimizedViTConfig.save_dir, f'best_model_stage{stage}.pdparams')
    else:
        checkpoint_path = os.path.join(OptimizedViTConfig.save_dir, f'checkpoint_stage{stage}_epoch_{epoch}.pdparams')

    paddle.save(checkpoint, checkpoint_path)
    return checkpoint_path


def save_training_history(train_losses, train_accuracies, val_losses, val_accuracies, stage=1):
    """ä½¿ç”¨csvä¿å­˜è®­ç»ƒå†å²"""
    history_path = os.path.join(OptimizedViTConfig.save_dir, f'training_history_stage{stage}.csv')

    with open(history_path, 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(['epoch', 'train_loss', 'train_accuracy', 'val_loss', 'val_accuracy'])

        for epoch, (train_loss, train_acc, val_loss, val_acc) in enumerate(
                zip(train_losses, train_accuracies, val_losses, val_accuracies), 1
        ):
            writer.writerow([epoch, train_loss, train_acc, val_loss, val_acc])

    print(f"ğŸ“ˆ è®­ç»ƒå†å²å·²ä¿å­˜: {history_path}")


def train_stage(stage=1, resume_checkpoint=None):
    """ä¸¤é˜¶æ®µè®­ç»ƒ - å¸¦æ–­ç‚¹ç»§ç»­åŠŸèƒ½"""
    if stage == 1:
        print("=" * 60)
        print("ç¬¬ä¸€é˜¶æ®µï¼š224å°ºå¯¸è®­ç»ƒ")
        print("=" * 60)
        image_size = OptimizedViTConfig.image_size_stage1
        batch_size = OptimizedViTConfig.batch_size_stage1
        num_epochs = OptimizedViTConfig.num_epochs_stage1
        learning_rate = OptimizedViTConfig.learning_rate_stage1
        use_mixup = False  # æš‚æ—¶å…³é—­MixUpï¼Œé¿å…æ•°æ®åŠ è½½é—®é¢˜
        # ä½¿ç”¨é…ç½®ä¸­çš„æ¢å¤è·¯å¾„ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ä¼ å…¥çš„å‚æ•°
        resume_path = OptimizedViTConfig.resume_stage1 if OptimizedViTConfig.resume_stage1 else resume_checkpoint
    else:
        print("=" * 60)
        print("ç¬¬äºŒé˜¶æ®µï¼š384å°ºå¯¸å¾®è°ƒ")
        print("=" * 60)
        image_size = OptimizedViTConfig.image_size_stage2
        batch_size = OptimizedViTConfig.batch_size_stage2
        num_epochs = OptimizedViTConfig.num_epochs_stage2
        learning_rate = OptimizedViTConfig.learning_rate_stage2
        use_mixup = False  # å¾®è°ƒæ—¶å…³é—­MixUp
        # ä½¿ç”¨é…ç½®ä¸­çš„æ¢å¤è·¯å¾„ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ä¼ å…¥çš„å‚æ•°
        resume_path = OptimizedViTConfig.resume_stage2 if OptimizedViTConfig.resume_stage2 else resume_checkpoint

    train_dir = os.path.join(OptimizedViTConfig.data_dir, 'train')
    val_dir = os.path.join(OptimizedViTConfig.data_dir, 'val')

    train_transforms = create_optimized_transforms(image_size, is_training=True)
    val_transforms = create_optimized_transforms(image_size, is_training=False)

    print("åŠ è½½è®­ç»ƒé›†...")
    train_dataset = FlowerDataset(train_dir, transform=train_transforms, use_mixup=use_mixup)
    print("åŠ è½½éªŒè¯é›†...")
    val_dataset = FlowerDataset(val_dir, transform=val_transforms, use_mixup=False)

    # ä½¿ç”¨å•è¿›ç¨‹æ•°æ®åŠ è½½ï¼Œé¿å…å¤šè¿›ç¨‹é—®é¢˜
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=0  # è®¾ç½®ä¸º0é¿å…å¤šè¿›ç¨‹é—®é¢˜
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0  # è®¾ç½®ä¸º0é¿å…å¤šè¿›ç¨‹é—®é¢˜
    )

    print(f"\né˜¶æ®µ{stage}é…ç½®:")
    print(f"å›¾åƒå°ºå¯¸: {image_size}")
    print(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"è®­ç»ƒé›†: {len(train_dataset)} å¼ å›¾ç‰‡")
    print(f"éªŒè¯é›†: {len(val_dataset)} å¼ å›¾ç‰‡")

    # åˆ›å»ºæ¨¡å‹
    model = create_model(image_size)

    total_steps = len(train_loader) * num_epochs
    optimizer, scheduler = create_optimizer_scheduler(
        model, total_steps, learning_rate, num_epochs, OptimizedViTConfig.warmup_epochs
    )

    # åˆå§‹åŒ–è®­ç»ƒçŠ¶æ€
    start_epoch = 0
    best_accuracy = 0.0
    train_losses = []
    train_accuracies = []
    val_losses = []
    val_accuracies = []

    # åŠ è½½æ£€æŸ¥ç‚¹ï¼ˆå¦‚æœæä¾›ï¼‰
    if resume_path:
        start_epoch, best_accuracy, train_losses, train_accuracies, val_losses, val_accuracies = load_checkpoint(
            model, optimizer, scheduler, resume_path
        )

    # ä½¿ç”¨æ ‡ç­¾å¹³æ»‘æŸå¤±
    criterion = LabelSmoothingCrossEntropy(smoothing=0.1)

    patience = 10  # å¢åŠ è€å¿ƒå€¼
    patience_counter = 0

    print(f"\nå¼€å§‹é˜¶æ®µ{stage}è®­ç»ƒä»epoch {start_epoch + 1}åˆ°{num_epochs}...")
    print("=" * 60)

    for epoch in range(start_epoch, num_epochs):
        current_epoch = epoch + 1
        print(f"\nEpoch {current_epoch}/{num_epochs}")
        print("-" * 50)

        # è®­ç»ƒé˜¶æ®µ
        model.train()
        total_loss = 0
        correct = 0
        total = 0
        start_time = time.time()

        for batch_idx, (data, target) in enumerate(train_loader):
            optimizer.clear_grad()

            # ç¡®ä¿æ•°æ®åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            data = data.astype('float32')
            target = target.astype('int64')  # ç¡®ä¿æ ‡ç­¾æ˜¯int64ç±»å‹

            output = model(data)
            loss = criterion(output, target)

            loss.backward()

            # æ³¨æ„ï¼šæ¢¯åº¦è£å‰ªå·²åœ¨ä¼˜åŒ–å™¨ä¸­è®¾ç½®ï¼Œä¸éœ€è¦å•ç‹¬è°ƒç”¨
            # åˆ é™¤ paddle.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

            optimizer.step()

            total_loss += loss.item()

            pred = output.argmax(axis=1)
            correct += (pred == target).sum().item()
            total += target.shape[0]

            if batch_idx % OptimizedViTConfig.log_interval == 0:
                current_lr = optimizer.get_lr()
                batch_acc = 100. * correct / total if total > 0 else 0
                print(
                    f'è®­ç»ƒ [{batch_idx}/{len(train_loader)}] Loss: {loss.item():.4f} Acc: {batch_acc:.1f}% LR: {current_lr:.2e}')

        avg_train_loss = total_loss / len(train_loader)
        train_accuracy = 100. * correct / total
        train_time = time.time() - start_time

        train_losses.append(avg_train_loss)
        train_accuracies.append(train_accuracy)

        print(f'è®­ç»ƒç»“æœ - æŸå¤±: {avg_train_loss:.4f}, å‡†ç¡®ç‡: {train_accuracy:.2f}%, æ—¶é—´: {train_time:.1f}ç§’')

        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0
        val_correct = 0
        val_total = 0

        with paddle.no_grad():
            for data, target in val_loader:
                data = data.astype('float32')
                target = target.astype('int64')

                output = model(data)
                loss = criterion(output, target)

                val_loss += loss.item()
                pred = output.argmax(axis=1)
                val_correct += (pred == target).sum().item()
                val_total += target.shape[0]

        avg_val_loss = val_loss / len(val_loader)
        val_accuracy = 100. * val_correct / val_total

        val_losses.append(avg_val_loss)
        val_accuracies.append(val_accuracy)

        print(f'éªŒè¯ç»“æœ - æŸå¤±: {avg_val_loss:.4f}, å‡†ç¡®ç‡: {val_accuracy:.2f}%')

        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹
        if val_accuracy > best_accuracy:
            best_accuracy = val_accuracy
            save_checkpoint(
                current_epoch, model, optimizer, scheduler, best_accuracy,
                train_losses, train_accuracies, val_losses, val_accuracies,
                stage=stage, is_best=True
            )
            patience_counter = 0
            print(f"ğŸš€ ä¿å­˜æœ€ä½³æ¨¡å‹ï¼Œå‡†ç¡®ç‡: {val_accuracy:.2f}%")
        else:
            patience_counter += 1
            print(f"â³ æ—©åœè®¡æ•°: {patience_counter}/{patience}")

        # æ¯5ä¸ªepochä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
        if current_epoch % 5 == 0:
            checkpoint_path = save_checkpoint(
                current_epoch, model, optimizer, scheduler, best_accuracy,
                train_losses, train_accuracies, val_losses, val_accuracies,
                stage=stage, is_best=False
            )
            print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}")

        # æ—©åœæ£€æŸ¥
        if patience_counter >= patience:
            print(f"ğŸ›‘ æ—©åœè§¦å‘ï¼Œåœ¨epoch {current_epoch}åœæ­¢è®­ç»ƒ")
            break

    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_checkpoint_path = save_checkpoint(
        num_epochs, model, optimizer, scheduler, best_accuracy,
        train_losses, train_accuracies, val_losses, val_accuracies,
        stage=stage, is_best=False
    )
    print(f"ğŸ’¾ ä¿å­˜æœ€ç»ˆæ¨¡å‹: {final_checkpoint_path}")

    # ä¿å­˜è®­ç»ƒå†å²åˆ°CSV
    save_training_history(train_losses, train_accuracies, val_losses, val_accuracies, stage)

    print(f"\nğŸ‰ é˜¶æ®µ{stage}è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ† æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_accuracy:.2f}%")

    return model, best_accuracy


def main():
    """ä¿®å¤åçš„ä¸»è®­ç»ƒå‡½æ•°"""
    # è®¾ç½®å†…å­˜ä¼˜åŒ–
    setup_memory_optimization()

    # è®¾ç½®éšæœºç§å­
    paddle.seed(42)
    np.random.seed(42)
    random.seed(42)

    print("å¼€å§‹ç¬¬ä¸€é˜¶æ®µè®­ç»ƒ...")
    try:
        model_stage1, best_acc_stage1 = train_stage(stage=1)

        if best_acc_stage1 > 45:
            print("\nå¼€å§‹ç¬¬äºŒé˜¶æ®µå¾®è°ƒ...")
            resume_path = os.path.join(OptimizedViTConfig.save_dir, 'best_model_stage1.pdparams')
            model_stage2, best_acc_stage2 = train_stage(stage=2, resume_checkpoint=resume_path)

            print(f"\nè®­ç»ƒæ€»ç»“:")
            print(f"ç¬¬ä¸€é˜¶æ®µ(224)æœ€ä½³å‡†ç¡®ç‡: {best_acc_stage1:.2f}%")
            print(f"ç¬¬äºŒé˜¶æ®µ(384)æœ€ä½³å‡†ç¡®ç‡: {best_acc_stage2:.2f}%")
            print(f"æå‡: {best_acc_stage2 - best_acc_stage1:+.2f}%")
        else:
            print(f"\nç¬¬ä¸€é˜¶æ®µå‡†ç¡®ç‡({best_acc_stage1:.2f}%)ä¸è¶³ï¼Œè·³è¿‡ç¬¬äºŒé˜¶æ®µå¾®è°ƒ")

    except Exception as e:
        print(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()