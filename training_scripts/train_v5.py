import os
# è®¾ç½®ç¯å¢ƒå˜é‡å‡å°‘å†…å­˜ç¢ç‰‡
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
import time
import copy
import numpy as np
import pandas as pd
from PIL import Image
import matplotlib.pyplot as plt


# è®¾ç½®è®¾å¤‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ä½¿ç”¨è®¾å¤‡: {device}")
if torch.cuda.is_available():
    print(f"GPUåç§°: {torch.cuda.get_device_name(0)}")
    print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024 ** 3:.1f} GB")


# è®¾ç½®éšæœºç§å­
def set_seed(seed=42):
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = True
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)


set_seed()


# é…ç½®å‚æ•° - å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬
class Config:
    data_dir = r'D:\ptcharm\project\èŠ±å‰åˆ†æ'
    num_classes = 100
    image_size = 224
    batch_size = 16  # å‡å°æ‰¹æ¬¡å¤§å°
    accumulation_steps = 2  # æ¢¯åº¦ç´¯ç§¯
    learning_rate = 0.1
    weight_decay = 5e-4
    num_epochs = 100
    save_dir = './output_wrn28_optimized'

    # WRNé…ç½®
    wrn_depth = 28
    wrn_width = 8
    dropout_rate = 0.3
    use_checkpoint = True  # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹

    os.makedirs(save_dir, exist_ok=True)


# ==================== WideResNetæ¨¡å‹ï¼ˆå¸¦æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼‰ ====================
class WideBasicBlock(nn.Module):
    def __init__(self, in_planes, out_planes, stride=1, dropout_rate=0.3):
        super(WideBasicBlock, self).__init__()
        self.bn1 = nn.BatchNorm2d(in_planes)
        self.relu1 = nn.ReLU(inplace=True)
        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_planes)
        self.relu2 = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False)
        self.dropout = nn.Dropout2d(p=dropout_rate)

        self.shortcut = nn.Sequential()
        if stride != 1 or in_planes != out_planes:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)
            )

    def forward(self, x):
        out = self.bn1(x)
        out = self.relu1(out)
        out = self.conv1(out)
        out = self.bn2(out)
        out = self.relu2(out)
        out = self.dropout(out)
        out = self.conv2(out)
        out += self.shortcut(x)
        return out


class WideResNet(nn.Module):
    def __init__(self, depth=28, widen_factor=8, dropout_rate=0.3, num_classes=100, use_checkpoint=True):
        super(WideResNet, self).__init__()
        self.use_checkpoint = use_checkpoint
        self.in_planes = 16
        self.n = (depth - 4) // 6
        nChannels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]

        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1, padding=1, bias=False)
        self.layer1 = self._make_layer(WideBasicBlock, nChannels[0], nChannels[1], stride=1, dropout_rate=dropout_rate)
        self.layer2 = self._make_layer(WideBasicBlock, nChannels[1], nChannels[2], stride=2, dropout_rate=dropout_rate)
        self.layer3 = self._make_layer(WideBasicBlock, nChannels[2], nChannels[3], stride=2, dropout_rate=dropout_rate)

        self.bn1 = nn.BatchNorm2d(nChannels[3])
        self.relu = nn.ReLU(inplace=True)
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(nChannels[3], num_classes)

        # æƒé‡åˆå§‹åŒ–
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def _make_layer(self, block, in_planes, out_planes, stride, dropout_rate):
        layers = [block(in_planes, out_planes, stride, dropout_rate)]
        for _ in range(1, self.n):
            layers.append(block(out_planes, out_planes, 1, dropout_rate))
        return nn.Sequential(*layers)

    def forward(self, x):
        out = self.conv1(x)

        # ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆä»…åœ¨è®­ç»ƒæ—¶ï¼‰
        if self.use_checkpoint and self.training:
            from torch.utils.checkpoint import checkpoint
            out = checkpoint(self.layer1, out)
            out = checkpoint(self.layer2, out)
            out = checkpoint(self.layer3, out)
        else:
            out = self.layer1(out)
            out = self.layer2(out)
            out = self.layer3(out)

        out = self.bn1(out)
        out = self.relu(out)
        out = self.avgpool(out)
        out = out.view(out.size(0), -1)
        out = self.fc(out)
        return out


# ==================== æ•°æ®åŠ è½½ ====================
class FlowerDataset(Dataset):
    def __init__(self, data_dir, transform=None, is_train=True):
        self.data_dir = data_dir
        self.transform = transform
        self.samples = []
        self.labels = []

        categories = sorted([d for d in os.listdir(data_dir) if d.isdigit()], key=int)
        self.label_mapping = {int(cat): idx for idx, cat in enumerate(categories)}

        print(f"åŠ è½½æ•°æ®é›†: {data_dir}")
        print(f"å‘ç°ç±»åˆ«: {len(categories)}ä¸ª")

        for category in categories:
            category_dir = os.path.join(data_dir, category)
            if os.path.isdir(category_dir):
                image_files = [f for f in os.listdir(category_dir)
                               if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
                for file in image_files:
                    self.samples.append(os.path.join(category_dir, file))
                    self.labels.append(self.label_mapping[int(category)])

        print(f"å›¾ç‰‡æ•°é‡: {len(self.samples)}")

    def __getitem__(self, idx):
        img_path = self.samples[idx]
        label = self.labels[idx]

        try:
            img = Image.open(img_path).convert('RGB')
            if self.transform:
                img = self.transform(img)
            return img, label
        except Exception as e:
            print(f"åŠ è½½å›¾ç‰‡å¤±è´¥: {img_path}, é”™è¯¯: {e}")
            dummy_img = torch.rand(3, Config.image_size, Config.image_size)
            return dummy_img, label

    def __len__(self):
        return len(self.samples)


def create_data_loaders():
    """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
    # WRNéœ€è¦æ›´å¼ºçš„æ•°æ®å¢å¼º
    train_transforms = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.RandomCrop(Config.image_size),
        transforms.RandomHorizontalFlip(0.5),
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
        transforms.RandomRotation(10),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    val_transforms = transforms.Compose([
        transforms.Resize((Config.image_size, Config.image_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    train_dataset = FlowerDataset(os.path.join(Config.data_dir, 'train'), transform=train_transforms)
    val_dataset = FlowerDataset(os.path.join(Config.data_dir, 'val'), transform=val_transforms)

    train_loader = DataLoader(
        train_dataset,
        batch_size=Config.batch_size,
        shuffle=True,
        num_workers=4,
        pin_memory=True
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=Config.batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )

    dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}
    print(f"è®­ç»ƒé›†å¤§å°: {dataset_sizes['train']}")
    print(f"éªŒè¯é›†å¤§å°: {dataset_sizes['val']}")

    return {'train': train_loader, 'val': val_loader}, dataset_sizes


# ==================== å†…å­˜ç›‘æ§å‡½æ•° ====================
def print_memory_usage(desc=""):
    """æ‰“å°GPUå†…å­˜ä½¿ç”¨æƒ…å†µ"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024 ** 3
        reserved = torch.cuda.memory_reserved() / 1024 ** 3
        max_allocated = torch.cuda.max_memory_allocated() / 1024 ** 3
        print(f"{desc}: å·²åˆ†é…: {allocated:.2f}GB, ä¿ç•™: {reserved:.2f}GB, å³°å€¼: {max_allocated:.2f}GB")


# ==================== è®­ç»ƒå‡½æ•°ï¼ˆä¿®å¤æ··åˆç²¾åº¦é—®é¢˜ï¼‰ ====================
def train_model_wrn(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, num_epochs=100):
    """WRNä¸“ç”¨è®­ç»ƒå‡½æ•°ï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆï¼‰"""
    since = time.time()
    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    # æ·»åŠ GradScalerç”¨äºæ··åˆç²¾åº¦è®­ç»ƒï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
    scaler = torch.cuda.amp.GradScaler() if hasattr(torch.cuda.amp, 'GradScaler') else None

    # æ¸…ç†GPUç¼“å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.reset_peak_memory_stats()

    train_loss_history = []
    train_acc_history = []
    val_loss_history = []
    val_acc_history = []

    print("å¼€å§‹è®­ç»ƒWRNï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆï¼‰...")
    print_memory_usage("è®­ç»ƒå¼€å§‹å‰")

    for epoch in range(num_epochs):
        print(f'Epoch {epoch + 1}/{num_epochs}')
        print('-' * 40)

        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()
            else:
                model.eval()

            running_loss = 0.0
            running_corrects = 0
            start_time = time.time()

            # åœ¨éªŒè¯é˜¶æ®µä½¿ç”¨no_gradå‡å°‘å†…å­˜ä½¿ç”¨
            with torch.set_grad_enabled(phase == 'train'):
                for batch_idx, (inputs, labels) in enumerate(dataloaders[phase]):
                    inputs = inputs.to(device, non_blocking=True)
                    labels = labels.to(device, non_blocking=True)

                    if phase == 'train':
                        # ä½¿ç”¨æ··åˆç²¾åº¦å‰å‘ä¼ æ’­ï¼ˆå…¼å®¹ä¸åŒPyTorchç‰ˆæœ¬ï¼‰
                        if scaler is not None:
                            # æ–°ç‰ˆæœ¬PyTorchçš„æ··åˆç²¾åº¦
                            with torch.cuda.amp.autocast():
                                outputs = model(inputs)
                                _, preds = torch.max(outputs, 1)
                                loss = criterion(outputs, labels)
                                loss = loss / Config.accumulation_steps  # æ¢¯åº¦ç´¯ç§¯

                            # ä½¿ç”¨scalerè¿›è¡Œåå‘ä¼ æ’­
                            scaler.scale(loss).backward()

                            # åªåœ¨ç´¯ç§¯æ­¥éª¤è¾¾åˆ°æ—¶æ›´æ–°æƒé‡
                            if (batch_idx + 1) % Config.accumulation_steps == 0:
                                scaler.step(optimizer)
                                scaler.update()
                                optimizer.zero_grad()
                        else:
                            # æ—§ç‰ˆæœ¬PyTorchï¼Œä¸ä½¿ç”¨æ··åˆç²¾åº¦
                            outputs = model(inputs)
                            _, preds = torch.max(outputs, 1)
                            loss = criterion(outputs, labels)
                            loss = loss / Config.accumulation_steps

                            loss.backward()
                            if (batch_idx + 1) % Config.accumulation_steps == 0:
                                optimizer.step()
                                optimizer.zero_grad()
                    else:
                        # éªŒè¯é˜¶æ®µä¸éœ€è¦æ··åˆç²¾åº¦
                        outputs = model(inputs)
                        _, preds = torch.max(outputs, 1)
                        loss = criterion(outputs, labels)

                    running_loss += loss.item() * inputs.size(0) * (
                        Config.accumulation_steps if phase == 'train' else 1)
                    running_corrects += torch.sum(preds == labels.data)

                    # æ¯50ä¸ªbatchæ‰“å°ä¸€æ¬¡å†…å­˜ä½¿ç”¨æƒ…å†µ
                    if batch_idx % 50 == 0:
                        print_memory_usage(f"Batch {batch_idx}")

            if phase == 'train':
                scheduler.step()

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]

            epoch_time = time.time() - start_time
            print(f'{phase:5} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Time: {epoch_time:.1f}s')

            if phase == 'train':
                train_loss_history.append(epoch_loss)
                train_acc_history.append(epoch_acc.cpu().numpy())
            else:
                val_loss_history.append(epoch_loss)
                val_acc_history.append(epoch_acc.cpu().numpy())

            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())
                print(f"ğŸ‰ æ–°çš„æœ€ä½³å‡†ç¡®ç‡: {best_acc:.4f}")

                # ç«‹å³ä¿å­˜æœ€ä½³æ¨¡å‹
                best_model_path = os.path.join(Config.save_dir, f'best_model_epoch_{epoch + 1}_acc_{best_acc:.4f}.pth')
                torch.save(best_model_wts, best_model_path)

        # æ¯20ä¸ªepochä¿å­˜æ£€æŸ¥ç‚¹
        if (epoch + 1) % 20 == 0:
            checkpoint_path = os.path.join(Config.save_dir, f'checkpoint_epoch_{epoch + 1}.pth')
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'best_acc': best_acc,
            }, checkpoint_path)
            print(f'æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}')

        # æ¸…ç†GPUç¼“å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    time_elapsed = time.time() - since
    print(f'è®­ç»ƒå®Œæˆï¼Œç”¨æ—¶ {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.4f}')

    model.load_state_dict(best_model_wts)
    return model, train_loss_history, train_acc_history, val_loss_history, val_acc_history


# ==================== ä¸»è®­ç»ƒæµç¨‹ ====================
def main():
    print("=== WRN-28å†…å­˜ä¼˜åŒ–è®­ç»ƒæ¨¡å¼ ===")

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("åŠ è½½æ•°æ®...")
    dataloaders, dataset_sizes = create_data_loaders()

    # åˆå§‹åŒ–WRN-28æ¨¡å‹ï¼ˆå¸¦æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼‰
    print("åˆå§‹åŒ–WRN-28æ¨¡å‹ï¼ˆå¸¦æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼‰...")
    model = WideResNet(
        depth=Config.wrn_depth,
        widen_factor=Config.wrn_width,
        dropout_rate=Config.dropout_rate,
        num_classes=Config.num_classes,
        use_checkpoint=Config.use_checkpoint
    )
    model = model.to(device)

    # æ‰“å°æ¨¡å‹å‚æ•°
    total_params = sum(p.numel() for p in model.parameters())
    print(f"æ€»å‚æ•°é‡: {total_params:,}")

    # å®šä¹‰æŸå¤±å‡½æ•° - ä½¿ç”¨æ ‡ç­¾å¹³æ»‘
    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

    # WRNä½¿ç”¨SGD + Momentum
    optimizer = optim.SGD(
        model.parameters(),
        lr=Config.learning_rate,
        momentum=0.9,
        weight_decay=Config.weight_decay,
        nesterov=True
    )

    # å­¦ä¹ ç‡è°ƒåº¦ - WRNä½¿ç”¨é˜¶æ¢¯ä¸‹é™
    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120, 160], gamma=0.2)

    # è®­ç»ƒæ¨¡å‹
    model, train_loss, train_acc, val_loss, val_acc = train_model_wrn(
        model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, Config.num_epochs
    )

    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_model_path = os.path.join(Config.save_dir, 'final_wrn28_model.pth')
    torch.save(model.state_dict(), final_model_path)
    print(f"æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: '{final_model_path}'")

    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    plt.plot(train_loss, label='è®­ç»ƒæŸå¤±')
    plt.plot(val_loss, label='éªŒè¯æŸå¤±')
    plt.title('è®­ç»ƒå’ŒéªŒè¯æŸå¤±')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(train_acc, label='è®­ç»ƒå‡†ç¡®ç‡')
    plt.plot(val_acc, label='éªŒè¯å‡†ç¡®ç‡')
    plt.title('è®­ç»ƒå’ŒéªŒè¯å‡†ç¡®ç‡')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.tight_layout()
    plt.savefig(os.path.join(Config.save_dir, 'training_history_wrn28.png'), dpi=150)
    plt.show()

    # ä¿å­˜è®­ç»ƒå†å²
    history = pd.DataFrame({
        'epoch': range(1, len(train_loss) + 1),
        'train_loss': train_loss,
        'train_accuracy': train_acc,
        'val_loss': val_loss,
        'val_accuracy': val_acc
    })
    history_path = os.path.join(Config.save_dir, 'training_history_wrn28.csv')
    history.to_csv(history_path, index=False)
    print(f"è®­ç»ƒå†å²å·²ä¿å­˜: {history_path}")

    print(f"\næœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {train_acc[-1]:.4f}")
    print(f"æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {val_acc[-1]:.4f}")


if __name__ == "__main__":
    main()