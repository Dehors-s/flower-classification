import torch
import paddle
import torch.nn as nn
import numpy as np
import os
import sys

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(__file__))

from vit_v1 import create_paddle_model, Config

# ==================== é…ç½®åŒºåŸŸ ====================
# ç›´æ¥æŒ‡å®šPaddlePaddleæ¨¡å‹è·¯å¾„
PADDLE_MODEL_PATH = r"D:\ptcharm\project\èŠ±å‰åˆ†æ\checkpoint_epoch_30.pdparams"
# æŒ‡å®šè¾“å‡ºçš„PyTorchæ¨¡å‹æ–‡ä»¶å
PYTORCH_MODEL_NAME = "pytorch_vit_epoch_30.pth"
# ================================================

print(f"æ­£åœ¨æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶: {PADDLE_MODEL_PATH}")


# PyTorchç‰ˆæœ¬çš„ViTæ¨¡å‹å®šä¹‰ï¼ˆä¸PaddlePaddleç‰ˆæœ¬ç»“æ„ç›¸åŒï¼‰
class PyTorchViT(nn.Module):
    def __init__(self, image_size=224, patch_size=16, num_classes=1000,
                 dim=384, depth=6, heads=8, mlp_ratio=4, dropout=0.1):
        super().__init__()

        self.patch_size = patch_size
        self.num_patches = (image_size // patch_size) ** 2
        patch_dim = 3 * patch_size ** 2

        # PatchåµŒå…¥
        self.patch_embed = nn.Conv2d(
            3, dim,
            kernel_size=patch_size,
            stride=patch_size
        )

        # ç±»åˆ«tokenå’Œä½ç½®ç¼–ç 
        self.cls_token = nn.Parameter(torch.zeros(1, 1, dim))
        self.pos_embedding = nn.Parameter(torch.zeros(1, self.num_patches + 1, dim))

        self.dropout = nn.Dropout(dropout)

        # Transformerå±‚
        mlp_dim = int(dim * mlp_ratio)
        self.encoder_layers = nn.ModuleList([
            PyTorchTransformerBlock(dim, heads, mlp_dim, dropout)
            for _ in range(depth)
        ])

        # å±‚å½’ä¸€åŒ–
        self.norm = nn.LayerNorm(dim)

        # åˆ†ç±»å¤´
        self.head = nn.Linear(dim, num_classes)

        # åˆå§‹åŒ–æƒé‡
        self.apply(self._init_weights)

    def _init_weights(self, m):
        if isinstance(m, nn.Linear):
            torch.nn.init.trunc_normal_(m.weight, std=0.02)
            if m.bias is not None:
                torch.nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.LayerNorm):
            torch.nn.init.constant_(m.bias, 0)
            torch.nn.init.constant_(m.weight, 1.0)
        elif isinstance(m, nn.Conv2d):
            torch.nn.init.trunc_normal_(m.weight, std=0.02)
            if m.bias is not None:
                torch.nn.init.constant_(m.bias, 0)

    def forward(self, x):
        B, C, H, W = x.shape

        # ä½¿ç”¨å·ç§¯è¿›è¡ŒpatchåµŒå…¥
        x = self.patch_embed(x)  # [B, dim, H//P, W//P]
        x = x.flatten(2)  # [B, dim, num_patches]
        x = x.transpose(1, 2)  # [B, num_patches, dim]

        # æ·»åŠ ç±»åˆ«token
        cls_tokens = self.cls_token.expand(B, -1, -1)
        x = torch.cat([cls_tokens, x], dim=1)

        # æ·»åŠ ä½ç½®ç¼–ç 
        x = x + self.pos_embedding
        x = self.dropout(x)

        # Transformerç¼–ç å™¨
        for layer in self.encoder_layers:
            x = layer(x)

        # åˆ†ç±»
        x = self.norm(x)
        x = x[:, 0]  # å–ç±»åˆ«token
        x = self.head(x)

        return x


class PyTorchTransformerBlock(nn.Module):
    def __init__(self, dim, heads, mlp_dim, dropout=0.1):
        super().__init__()
        self.norm1 = nn.LayerNorm(dim)
        self.attn = nn.MultiheadAttention(dim, heads, dropout=dropout, batch_first=True)
        self.norm2 = nn.LayerNorm(dim)
        self.mlp = nn.Sequential(
            nn.Linear(dim, mlp_dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(mlp_dim, dim),
            nn.Dropout(dropout)
        )
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        # è‡ªæ³¨æ„åŠ›
        residual = x
        x = self.norm1(x)
        attn_output, _ = self.attn(x, x, x)
        x = residual + self.dropout(attn_output)

        # MLP
        residual = x
        x = self.norm2(x)
        mlp_output = self.mlp(x)
        x = residual + self.dropout(mlp_output)

        return x


def convert_paddle_to_pytorch(paddle_model_path=None):
    """å°†PaddlePaddleæ¨¡å‹è½¬æ¢ä¸ºPyTorchæ¨¡å‹"""
    print("=" * 60)
    print("å¼€å§‹è½¬æ¢PaddlePaddleæ¨¡å‹åˆ°PyTorch")
    print("=" * 60)

    # å¦‚æœæœªæä¾›è·¯å¾„ï¼Œä½¿ç”¨é…ç½®çš„è·¯å¾„
    if paddle_model_path is None:
        paddle_model_path = PADDLE_MODEL_PATH

    print(f"æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶: {paddle_model_path}")

    if not os.path.exists(paddle_model_path):
        # å°è¯•åœ¨å¸¸è§ä½ç½®æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
        possible_paths = [
            paddle_model_path,
            os.path.join(os.path.dirname(__file__), 'best_model.pdparams'),
            os.path.join(os.path.dirname(__file__), 'best_model2.pdparams'),
            os.path.join(os.path.dirname(__file__), 'output_vit_fixed', 'best_model.pdparams'),
            'best_model.pdparams',
            'best_model2.pdparams',
            os.path.expanduser('~/best_model.pdparams'),
        ]

        found = False
        for path in possible_paths:
            if os.path.exists(path):
                paddle_model_path = path
                found = True
                print(f"âœ… æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {paddle_model_path}")
                break

        if not found:
            print("âŒ æ‰¾ä¸åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶")
            print("è¯·æä¾›æ­£ç¡®çš„æ¨¡å‹è·¯å¾„æˆ–å…ˆè®­ç»ƒæ¨¡å‹")
            return None

    # åˆ›å»ºPaddlePaddleæ¨¡å‹å¹¶åŠ è½½æƒé‡
    paddle_model = create_paddle_model()

    try:
        # åŠ è½½PaddlePaddleæƒé‡
        paddle_state_dict = paddle.load(paddle_model_path)
        paddle_model.set_state_dict(paddle_state_dict)
        paddle_model.eval()
        print(f"âœ… å·²åŠ è½½PaddlePaddleæƒé‡: {paddle_model_path}")
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        return None

    # åˆ›å»ºPyTorchæ¨¡å‹
    pytorch_model = PyTorchViT(
        image_size=Config.image_size,
        patch_size=16,
        num_classes=Config.num_classes,
        dim=384,
        depth=6,
        heads=8,
        mlp_ratio=4,
        dropout=0.1
    )
    pytorch_model.eval()
    print("âœ… å·²åˆ›å»ºPyTorchæ¨¡å‹")

    # è½¬æ¢æƒé‡
    pytorch_state_dict = {}

    for paddle_key, paddle_param in paddle_model.state_dict().items():
        # è½¬æ¢å‚æ•°æ ¼å¼
        param_np = paddle_param.numpy()

        # å¤„ç†ä¸åŒå½¢çŠ¶çš„å‚æ•°
        if paddle_param.ndim == 4:  # å·ç§¯æƒé‡ [out_c, in_c, h, w]
            param_torch = torch.from_numpy(param_np)
            pytorch_key = paddle_key

        elif paddle_param.ndim == 2:  # çº¿æ€§æƒé‡
            # PaddlePaddle: [out_features, in_features]
            # PyTorch: [in_features, out_features]
            # éœ€è¦è½¬ç½®
            param_torch = torch.from_numpy(param_np).T
            pytorch_key = paddle_key

        elif paddle_param.ndim == 1:  # åç½®æˆ–å½’ä¸€åŒ–å‚æ•°
            param_torch = torch.from_numpy(param_np)
            pytorch_key = paddle_key

        elif paddle_param.ndim == 3:  # cls_token å’Œ pos_embedding
            param_torch = torch.from_numpy(param_np)
            pytorch_key = paddle_key

        else:
            print(f"âš ï¸  æœªçŸ¥ç»´åº¦: {paddle_key} - {paddle_param.shape}")
            continue

        pytorch_state_dict[pytorch_key] = param_torch
        print(f"âœ… è½¬æ¢: {paddle_key} {paddle_param.shape} -> {pytorch_key} {param_torch.shape}")

    # ç‰¹æ®Šå¤„ç†å¤šå¤´æ³¨æ„åŠ›æƒé‡
    print("\nå¤„ç†å¤šå¤´æ³¨æ„åŠ›æƒé‡...")

    # å¯¹äºæ¯ä¸ªTransformerå±‚ï¼Œå¤„ç†å¤šå¤´æ³¨æ„åŠ›
    for i in range(6):  # depth=6
        # è·å–Qã€Kã€Væƒé‡å’Œåç½®
        q_weight = paddle_model.state_dict()[f'encoder_layers.{i}.attn.q_proj.weight'].numpy()
        k_weight = paddle_model.state_dict()[f'encoder_layers.{i}.attn.k_proj.weight'].numpy()
        v_weight = paddle_model.state_dict()[f'encoder_layers.{i}.attn.v_proj.weight'].numpy()

        q_bias = paddle_model.state_dict()[f'encoder_layers.{i}.attn.q_proj.bias'].numpy()
        k_bias = paddle_model.state_dict()[f'encoder_layers.{i}.attn.k_proj.bias'].numpy()
        v_bias = paddle_model.state_dict()[f'encoder_layers.{i}.attn.v_proj.bias'].numpy()

        # åˆå¹¶QKVæƒé‡ (PyTorch MultiheadAttentionéœ€è¦è¿™ç§æ ¼å¼)
        # æ³¨æ„ï¼šéœ€è¦è½¬ç½®ï¼Œå› ä¸ºPaddlePaddleå’ŒPyTorchçš„çº¿æ€§å±‚æƒé‡å½¢çŠ¶ä¸åŒ
        in_proj_weight = np.concatenate([q_weight.T, k_weight.T, v_weight.T], axis=0)
        in_proj_bias = np.concatenate([q_bias, k_bias, v_bias], axis=0)

        pytorch_state_dict[f'encoder_layers.{i}.attn.in_proj_weight'] = torch.from_numpy(in_proj_weight)
        pytorch_state_dict[f'encoder_layers.{i}.attn.in_proj_bias'] = torch.from_numpy(in_proj_bias)

        # è¾“å‡ºæŠ•å½±å±‚æƒé‡ä¹Ÿéœ€è¦è½¬ç½®
        out_proj_weight = paddle_model.state_dict()[f'encoder_layers.{i}.attn.out_proj.weight'].numpy()
        out_proj_bias = paddle_model.state_dict()[f'encoder_layers.{i}.attn.out_proj.bias'].numpy()

        pytorch_state_dict[f'encoder_layers.{i}.attn.out_proj.weight'] = torch.from_numpy(out_proj_weight.T)
        pytorch_state_dict[f'encoder_layers.{i}.attn.out_proj.bias'] = torch.from_numpy(out_proj_bias)

        print(f"âœ… å¤„ç†æ³¨æ„åŠ›å±‚ {i}: QKVæƒé‡åˆå¹¶å®Œæˆ")

    # åŠ è½½æƒé‡åˆ°PyTorchæ¨¡å‹
    try:
        missing_keys, unexpected_keys = pytorch_model.load_state_dict(pytorch_state_dict, strict=False)

        if missing_keys:
            print(f"âš ï¸  ç¼ºå¤±çš„é”®: {missing_keys}")
        if unexpected_keys:
            print(f"âš ï¸  æ„å¤–çš„é”®: {unexpected_keys}")

        print("âœ… æƒé‡åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æƒé‡åŠ è½½å¤±è´¥: {e}")
        return None

    # ä¿å­˜PyTorchæ¨¡å‹ - ä½¿ç”¨é…ç½®çš„æ–‡ä»¶å
    pytorch_model_path = os.path.join(os.path.dirname(paddle_model_path), PYTORCH_MODEL_NAME)
    torch.save({
        'model_state_dict': pytorch_model.state_dict(),
        'config': {
            'image_size': Config.image_size,
            'patch_size': 16,
            'num_classes': Config.num_classes,
            'dim': 384,
            'depth': 6,
            'heads': 8,
            'mlp_ratio': 4,
            'dropout': 0.1
        }
    }, pytorch_model_path)

    print(f"ğŸ’¾ PyTorchæ¨¡å‹å·²ä¿å­˜: {pytorch_model_path}")

    # éªŒè¯è½¬æ¢ç»“æœ
    print("\n" + "=" * 60)
    print("éªŒè¯è½¬æ¢ç»“æœ")
    print("=" * 60)

    # åˆ›å»ºç›¸åŒçš„æµ‹è¯•è¾“å…¥
    np.random.seed(42)
    test_data = np.random.randn(2, 3, Config.image_size, Config.image_size).astype(np.float32)

    # PaddlePaddleæ¨ç†
    paddle_input = paddle.to_tensor(test_data)
    with paddle.no_grad():
        paddle_output = paddle_model(paddle_input)

    # PyTorchæ¨ç†
    torch_input = torch.from_numpy(test_data)
    with torch.no_grad():
        torch_output = pytorch_model(torch_input)

    # æ¯”è¾ƒè¾“å‡º
    paddle_output_np = paddle_output.numpy()
    torch_output_np = torch_output.numpy()

    print(f"Paddleè¾“å‡ºå½¢çŠ¶: {paddle_output_np.shape}")
    print(f"PyTorchè¾“å‡ºå½¢çŠ¶: {torch_output_np.shape}")

    # è®¡ç®—å·®å¼‚
    diff = np.abs(paddle_output_np - torch_output_np)
    max_diff = np.max(diff)
    mean_diff = np.mean(diff)

    print(f"æœ€å¤§å·®å¼‚: {max_diff:.6f}")
    print(f"å¹³å‡å·®å¼‚: {mean_diff:.6f}")

    if max_diff < 1e-4:
        print("âœ… è½¬æ¢æˆåŠŸï¼è¾“å‡ºåŸºæœ¬ä¸€è‡´")
    else:
        print("âš ï¸  è¾“å‡ºå­˜åœ¨å·®å¼‚ï¼Œä½†æ¨¡å‹ç»“æ„å·²è½¬æ¢å®Œæˆ")

    return pytorch_model


def load_pytorch_model(model_path=None):
    """åŠ è½½è½¬æ¢åçš„PyTorchæ¨¡å‹"""
    if model_path is None:
        # ä½¿ç”¨é…ç½®çš„æ–‡ä»¶åä½œä¸ºé»˜è®¤è·¯å¾„
        current_dir = os.path.dirname(__file__)
        model_path = os.path.join(current_dir, PYTORCH_MODEL_NAME)

    if not os.path.exists(model_path):
        print(f"âŒ æ‰¾ä¸åˆ°PyTorchæ¨¡å‹: {model_path}")
        return None

    # åŠ è½½æ¨¡å‹é…ç½®
    checkpoint = torch.load(model_path)
    config = checkpoint['config']

    # åˆ›å»ºæ¨¡å‹
    model = PyTorchViT(
        image_size=config['image_size'],
        patch_size=config['patch_size'],
        num_classes=config['num_classes'],
        dim=config['dim'],
        depth=config['depth'],
        heads=config['heads'],
        mlp_ratio=config['mlp_ratio'],
        dropout=config['dropout']
    )

    # åŠ è½½æƒé‡
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()

    print(f"âœ… å·²åŠ è½½PyTorchæ¨¡å‹: {model_path}")
    return model


if __name__ == "__main__":
    # ä½¿ç”¨é…ç½®çš„è·¯å¾„ç›´æ¥è½¬æ¢æ¨¡å‹
    pytorch_model = convert_paddle_to_pytorch(PADDLE_MODEL_PATH)

    if pytorch_model is not None:
        print("\nğŸ‰ æ¨¡å‹è½¬æ¢å®Œæˆï¼")
        print(f"è½¬æ¢åçš„æ¨¡å‹å·²ä¿å­˜ä¸º: {PYTORCH_MODEL_NAME}")
        print("æ‚¨å¯ä»¥ä½¿ç”¨ load_pytorch_model() å‡½æ•°åŠ è½½è½¬æ¢åçš„æ¨¡å‹")

        # æµ‹è¯•åŠ è½½åŠŸèƒ½
        loaded_model = load_pytorch_model()
        if loaded_model:
            print("âœ… æ¨¡å‹åŠ è½½æµ‹è¯•æˆåŠŸï¼")